{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TensorFlow and the RNEM model on the MovieLens dataset to recommend a movie to a user based on their past ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tfds.load(name=\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "df = tfds.as_dataframe(dataset)\n",
    "\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map movie and user IDs to contiguous integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "unique_movies = df[\"movie_id\"].unique()\n",
    "unique_users = df[\"user_id\"].unique()\n",
    "movie_id_map = dict(zip(unique_movies, range(len(unique_movies))))\n",
    "user_id_map = dict(zip(unique_users, range(len(unique_users))))\n",
    "train_df[\"movie_id\"] = train_df[\"movie_id\"].map(movie_id_map)\n",
    "train_df[\"user_id\"] = train_df[\"user_id\"].map(user_id_map)\n",
    "test_df[\"movie_id\"] = test_df[\"movie_id\"].map(movie_id_map)\n",
    "test_df[\"user_id\"] = test_df[\"user_id\"].map(user_id_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "num_movies = len(unique_movies)\n",
    "num_users = len(unique_users)\n",
    "num_ratings = len(df)\n",
    "num_relations = 2\n",
    "num_entities = num_movies + num_user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RNEM model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def RNEM(num_relations, num_entities, hidden_size):\n",
    "    # Define placeholders for input data\n",
    "    relations = tf.placeholder(tf.float32, [None, num_relations])\n",
    "    entities = tf.placeholder(tf.float32, [None, num_entities])\n",
    "\n",
    "    # Define a fully connected layer to encode the relations\n",
    "    relations_encoding = tf.layers.dense(relations, hidden_size, activation=tf.nn.relu)\n",
    "\n",
    "    # Define a fully connected layer to encode the entities\n",
    "    entities_encoding = tf.layers.dense(entities, hidden_size, activation=tf.nn.relu)\n",
    "\n",
    "    # Define a matrix multiplication layer to compute the likelihoods of each relation\n",
    "    logits = tf.matmul(relations_encoding, tf.transpose(entities_encoding))\n",
    "\n",
    "    # Define a sigmoid activation function to compute the probabilities\n",
    "    probabilities = tf.nn.sigmoid(logits)\n",
    "\n",
    "    # Define a placeholder for the ground truth data\n",
    "    ground_truth = tf.placeholder(tf.float32, [None, num_relations])\n",
    "\n",
    "    # Define a binary cross-entropy loss function\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=ground_truth, logits=logits))\n",
    "\n",
    "    # Define an optimizer to minimize the loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "    # Return the model components\n",
    "    return relations, entities, probabilities, ground_truth, loss, optimizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the RNEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 50\n",
    "relations, entities, probabilities, ground_truth, loss, optimizer = RNEM(num_relations, num_entities, hidden_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a TensorFlow session and run the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        # Sample a batch of training data\n",
    "        batch_size = 1000\n",
    "        indices = np.random.choice(len(train_df), batch_size)\n",
    "        batch_relations = np.zeros((batch_size, num_relations))\n",
    "        batch_entities = np.zeros((batch_size, num_entities))\n",
    "        batch_ground_truth = np.zeros((batch_size, num_relations))\n",
    "        for j, index in enumerate(indices):\n",
    "            row = train_df.iloc[index]\n",
    "            batch_relations[j, 0] = 1\n",
    "            batch_entities[j, row[\"user_id\"]] = 1\n",
    "            batch_entities[j, num_users + row[\"movie_id\"]] = 1\n",
    "            batch_ground_truth[j, 0] = row[\"rating\"]\n",
    "\n",
    "           \n",
    "           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the optimizer on the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "feed_dict = {relations: batch_relations, entities: batch_entities, ground_truth: batch_ground_truth}\n",
    "sess.run(optimizer, feed_dict=feed_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the model predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_relations = np.zeros((len(test_df), num_relations))\n",
    "test_entities = np.zeros((len(test_df), num_entities))\n",
    "for j, row in test_df.iterrows():\n",
    "    test_relations[j, 0] = 1\n",
    "    test_entities[j, row[\"user_id\"]] = 1\n",
    "    test_entities[j, num_users + row[\"movie_id\"]] = 1\n",
    "test_probabilities = sess.run(probabilities, feed_dict={relations: test_relations, entities: test_entities})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Compute the probabilities for each movie and print out the recommended movie based on user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    user_id = 0\n",
    "    user_entities = np.zeros((num_users, num_entities))\n",
    "    user_entities[:, user_id] = 1\n",
    "    movie_entities = np.zeros((num_movies, num_entities))\n",
    "    movie_entities[:, num_users:] = np.eye(num_movies)\n",
    "    user_relations = np.zeros((num_users, num_relations))\n",
    "    user_relations[:, 0] = 1\n",
    "    feed_dict = {relations: user_relations, entities: np.concatenate([user_entities, movie_entities], axis=0)}\n",
    "    user_probabilities = sess.run(probabilities, feed_dict=feed_dict)[0, num_users:]\n",
    "    top_indices = np.argsort(user_probabilities)[::-1][:10]\n",
    "    top_movies = [df[df[\"movie_id\"] == movie_id_map[index]].iloc[0][\"movie_title\"] for index in top_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Top recommended movies for user %d:\" % user_id)\n",
    "    for i, movie in enumerate(top_movies):\n",
    "        print(\"%d. %s\" % (i + 1, movie))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Area Under Curve (AUC) metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "test_ground_truth = np.array(test_df[\"rating\"])\n",
    "auc_score = roc_auc_score(test_ground_truth, test_probabilities)\n",
    "print(\"AUC score:\", auc_score)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
